{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be23887f-93fb-422a-84a0-9b1cb72f7b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbors Implementation\n",
    "# Complete code for both classification (Iris) and regression (Turnout) tasks\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f446a71-575f-4bb0-becb-433e1e443c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 1. IRIS DATASET - CLASSIFICATION\n",
    "# =============================================================================\n",
    "\n",
    "# Method 1: Loading Iris Dataset from URL\n",
    "def load_iris_from_url():\n",
    "    \"\"\"Load Iris dataset from UCI repository\"\"\"\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "    column_names = ['sepal length', 'sepal width', 'petal length', 'petal width', 'class']\n",
    "    dataset = pd.read_csv(url, names=column_names)\n",
    "    return dataset\n",
    "\n",
    "# Method 2: Loading Iris Dataset from sklearn (Recommended)\n",
    "def load_iris_from_sklearn():\n",
    "    \"\"\"Load Iris dataset from sklearn and convert to DataFrame\"\"\"\n",
    "    # Load the Iris dataset\n",
    "    x_bunch = load_iris()\n",
    "    \n",
    "    # Convert to DataFrame with proper column names\n",
    "    combined_data = np.c_[x_bunch.data, x_bunch.target]\n",
    "    df_columns = x_bunch.feature_names + ['target']\n",
    "    iris_df = pd.DataFrame(data=combined_data, columns=df_columns)\n",
    "    \n",
    "    # Replace numeric targets with class names\n",
    "    t1 = pd.DataFrame(x_bunch.target)\n",
    "    t1.replace(0, x_bunch.target_names[0], inplace=True)\n",
    "    t1.replace(1, x_bunch.target_names[1], inplace=True)\n",
    "    t1.replace(2, x_bunch.target_names[2], inplace=True)\n",
    "    \n",
    "    # Create final DataFrame with named targets\n",
    "    iris_df_named = pd.DataFrame(np.c_[x_bunch.data, t1], \n",
    "                                columns=x_bunch.feature_names + ['target'])\n",
    "    \n",
    "    return iris_df_named, x_bunch\n",
    "\n",
    "# Data Preprocessing for Classification\n",
    "def preprocess_iris_data(iris_df):\n",
    "    \"\"\"Preprocess Iris data for KNN classification\"\"\"\n",
    "    # Separate features and target\n",
    "    X = iris_df.drop('target', axis=1)\n",
    "    y = iris_df['target']\n",
    "    \n",
    "    # Min-Max Scaling (normalize features to 0-1 range)\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.25, random_state=0\n",
    "    )\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, scaler\n",
    "\n",
    "# KNN Classification Implementation\n",
    "def train_knn_classifier(X_train, y_train, n_neighbors=5):\n",
    "    \"\"\"Train KNN classifier\"\"\"\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn_classifier.fit(X_train, y_train)\n",
    "    return knn_classifier\n",
    "\n",
    "# Model Evaluation\n",
    "def evaluate_classifier(model, X_test, y_test):\n",
    "    \"\"\"Evaluate KNN classifier performance\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Classification Report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Accuracy Score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\nAccuracy Score: {accuracy*100:.2f}%\")\n",
    "    \n",
    "    return y_pred, accuracy\n",
    "\n",
    "# Find Optimal K Value\n",
    "def find_optimal_k(X_train, X_test, y_train, y_test, max_k=113):\n",
    "    \"\"\"Find optimal K value by plotting error rates\"\"\"\n",
    "    error_rate = []\n",
    "    \n",
    "    # Calculate error rates for different K values\n",
    "    for i in range(1, max_k):\n",
    "        knn = KNeighborsClassifier(n_neighbors=i)\n",
    "        knn.fit(X_train, y_train)\n",
    "        pred_i = knn.predict(X_test)\n",
    "        error_rate.append(np.mean(pred_i != y_test))\n",
    "    \n",
    "    # Plot error rate vs K value\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    plt.plot(range(1, len(error_rate) + 1), error_rate,\n",
    "             color='red', linestyle='dashed', marker='o',\n",
    "             markerfacecolor='blue', markersize=10)\n",
    "    plt.xlabel('Value of K')\n",
    "    plt.ylabel('Error Rate')\n",
    "    plt.title('Error Rate vs. K Value for Iris Dataset')\n",
    "    plt.show()\n",
    "    \n",
    "    # Find K with minimum error\n",
    "    optimal_k = np.argmin(error_rate) + 1\n",
    "    print(f\"Optimal K value: {optimal_k}\")\n",
    "    print(f\"Minimum error rate: {min(error_rate):.4f}\")\n",
    "    \n",
    "    return optimal_k, error_rate\n",
    "\n",
    "# Single Entry Prediction\n",
    "def predict_single_entry(model, scaler, new_data):\n",
    "    \"\"\"Predict class for a single new data point\"\"\"\n",
    "    # Scale the new data using the same scaler\n",
    "    scaled_new_data = scaler.transform(new_data)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(scaled_new_data)\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9dbde9-bd97-4d81-9981-6f0f9355b7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 2. TURNOUT DATASET - REGRESSION\n",
    "# =============================================================================\n",
    "\n",
    "def load_turnout_data(file_path=\"turnout.csv\"):\n",
    "    \"\"\"Load turnout dataset for regression\"\"\"\n",
    "    turnout_df = pd.read_csv(file_path)\n",
    "    return turnout_df\n",
    "\n",
    "def preprocess_turnout_data(turnout_df):\n",
    "    \"\"\"Preprocess turnout data for KNN regression\"\"\"\n",
    "    # Separate features and target\n",
    "    X = turnout_df.drop('educate', axis=1)  # 'educate' is the continuous target\n",
    "    y = turnout_df['educate']\n",
    "    \n",
    "    # Label encode categorical variables (e.g., 'race' column)\n",
    "    le = LabelEncoder()\n",
    "    X['race'] = le.fit_transform(X['race'])\n",
    "    \n",
    "    # Standard Scaling for regression\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.20, random_state=0\n",
    "    )\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, scaler, le\n",
    "\n",
    "def train_knn_regressor(X_train, y_train, n_neighbors=10):\n",
    "    \"\"\"Train KNN regressor\"\"\"\n",
    "    knn_regressor = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "    knn_regressor.fit(X_train, y_train)\n",
    "    return knn_regressor\n",
    "\n",
    "def evaluate_regressor(model, X_test, y_test):\n",
    "    \"\"\"Evaluate KNN regressor performance\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate regression metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "    print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "    \n",
    "    return y_pred, mae, mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4883024-617c-44e3-a6db-c401991ff2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 3. MAIN EXECUTION FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def run_iris_classification():\n",
    "    \"\"\"Complete workflow for Iris classification\"\"\"\n",
    "    print(\"=== IRIS DATASET CLASSIFICATION ===\")\n",
    "    \n",
    "    # Load data\n",
    "    iris_df, x_bunch = load_iris_from_sklearn()\n",
    "    print(f\"Dataset shape: {iris_df.shape}\")\n",
    "    print(f\"Classes: {x_bunch.target_names}\")\n",
    "    \n",
    "    # Preprocess data\n",
    "    X_train, X_test, y_train, y_test, scaler = preprocess_iris_data(iris_df)\n",
    "    \n",
    "    # Train initial model\n",
    "    print(\"\\n--- Training with K=5 ---\")\n",
    "    knn_model = train_knn_classifier(X_train, y_train, n_neighbors=5)\n",
    "    evaluate_classifier(knn_model, X_test, y_test)\n",
    "    \n",
    "    # Find optimal K\n",
    "    print(\"\\n--- Finding Optimal K ---\")\n",
    "    optimal_k, error_rates = find_optimal_k(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    # Train with optimal K\n",
    "    print(f\"\\n--- Training with Optimal K={optimal_k} ---\")\n",
    "    knn_optimal = train_knn_classifier(X_train, y_train, n_neighbors=optimal_k)\n",
    "    evaluate_classifier(knn_optimal, X_test, y_test)\n",
    "    \n",
    "    # Example predictions\n",
    "    print(\"\\n--- Single Entry Predictions ---\")\n",
    "    new_samples = [\n",
    "        np.array([[5.0, 3.2, 1.2, 0.2]]),  # Expected: setosa\n",
    "        np.array([[6.0, 2.2, 5.0, 1.5]]),  # Expected: versicolor\n",
    "        np.array([[7.0, 3.2, 6.0, 2.0]])   # Expected: virginica\n",
    "    ]\n",
    "    \n",
    "    for i, sample in enumerate(new_samples, 1):\n",
    "        prediction = predict_single_entry(knn_optimal, scaler, sample)\n",
    "        print(f\"Sample {i}: {sample.flatten()} -> Predicted: {prediction[0]}\")\n",
    "\n",
    "def run_turnout_regression():\n",
    "    \"\"\"Complete workflow for Turnout regression\"\"\"\n",
    "    print(\"\\n=== TURNOUT DATASET REGRESSION ===\")\n",
    "    \n",
    "    try:\n",
    "        # Load data\n",
    "        turnout_df = load_turnout_data()\n",
    "        print(f\"Dataset shape: {turnout_df.shape}\")\n",
    "        \n",
    "        # Preprocess data\n",
    "        X_train, X_test, y_train, y_test, scaler, le = preprocess_turnout_data(turnout_df)\n",
    "        \n",
    "        # Train regressor\n",
    "        print(\"\\n--- Training KNN Regressor ---\")\n",
    "        knn_regressor = train_knn_regressor(X_train, y_train, n_neighbors=10)\n",
    "        \n",
    "        # Evaluate regressor\n",
    "        evaluate_regressor(knn_regressor, X_test, y_test)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"turnout.csv file not found. Please ensure the file is available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db46e5f-b16d-42b2-8b5f-ecc7650c52d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 4. EXAMPLE USAGE\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run Iris classification example\n",
    "    run_iris_classification()\n",
    "    \n",
    "    # Run Turnout regression example (if data available)\n",
    "    run_turnout_regression()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
