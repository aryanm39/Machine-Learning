{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#1. Import libraries/packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score,mean_squared_error\n",
        "\n",
        "#2. Loading the data\n",
        "data = pd.read_csv('datasets/Fish.csv')\n",
        "print(data.sample(5))\n",
        "print(data.shape)\n",
        "print(data.isnull().sum())\n",
        "print(data.columns)\n",
        "data.dropna()\n",
        "print(data.shape)\n",
        "X = data[['Length1','Length2','Length3','Height','Width']]\n",
        "y = data['Weight']\n",
        "\n",
        "#3. Visualizing the data\n",
        "plt.subplot(2,2,1)\n",
        "plt.scatter(X['Length1'],y,color='red',label='Length1')\n",
        "plt.subplot(2,2,2)\n",
        "plt.scatter(X['Length2'],y,color='red',label='Length2')\n",
        "plt.subplot(2,2,3)\n",
        "plt.scatter(X['Length3'],y,color='red',label='Length3')\n",
        "plt.subplot(2,2,4)\n",
        "plt.scatter(X['Height'],y,color='blue',label='Height')\n",
        "plt.scatter(X['Width'],y,color='green',label='Width')\n",
        "plt.show()\n",
        "\n",
        "#4. Splitting our Data set in Dependent and Independent variables.\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.30,random_state=15)\n",
        "\n",
        "\n",
        "#5. Performing simple linear regression\n",
        "regressor= LinearRegression()\n",
        "regressor.fit(X_train,y_train)\n",
        "#Test Accuracy\n",
        "accuracy = regressor.score(X_test,y_test)\n",
        "print(\"\\n\\n Accuracy of model =\",accuracy)\n",
        "print(\"Coeficients\",regressor.coef_)\n",
        "print(\"Intercepts\",regressor.intercept_)\n",
        "\n",
        "#6. Residual analysis(Check the results of model fitting to know whether the model is satisfactory)\n",
        "plt.subplot(2,2,1)\n",
        "plt.scatter(X_test['Length1'],y_test,color='green')\n",
        "plt.plot(X_train['Length1'],regressor.predict(X_train),color=\"red\",linewidth=1)\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.scatter(X_test['Length2'],y_test,color='green')\n",
        "plt.plot(X_train['Length2'],regressor.predict(X_train),color=\"red\",linewidth=1)\n",
        "\n",
        "plt.subplot(2,2,3)\n",
        "plt.scatter(X_test['Length3'],y_test,color='green')\n",
        "plt.plot(X_train['Length3'],regressor.predict(X_train),color=\"red\",linewidth=1)\n",
        "\n",
        "plt.subplot(2,2,4)\n",
        "plt.scatter(X_test['Height'],y_test,color='green')\n",
        "plt.scatter(X_test['Width'],y_test,color='blue')\n",
        "plt.plot(X_train[['Height']],regressor.predict(X_train),color=\"red\",linewidth=1)\n",
        "plt.plot(X_train[['Width']],regressor.predict(X_train),color=\"red\",linewidth=1)\n",
        "\n",
        "plt.title('Regression(Test Set)')\n",
        "plt.xlabel('Independent')\n",
        "plt.ylabel('Weight')\n",
        "plt.show()\n",
        "\n",
        "plt.subplot(2,2,1)\n",
        "plt.scatter(X_train['Length1'],y_train,color=\"blue\")\n",
        "plt.plot(X_train['Length1'],regressor.predict(X_train),color=\"red\",linewidth=1)\n",
        "plt.subplot(2,2,2)\n",
        "plt.scatter(X_train['Length2'],y_train,color=\"blue\")\n",
        "plt.plot(X_train['Length2'],regressor.predict(X_train),color=\"red\",linewidth=1)\n",
        "plt.subplot(2,2,3)\n",
        "plt.plot(X_train['Length3'],regressor.predict(X_train),color=\"red\",linewidth=1)\n",
        "plt.subplot(2,2,4)\n",
        "plt.scatter(X_train['Height'],y_train,color=\"green\")\n",
        "plt.scatter(X_train['Width'],y_train,color=\"blue\")\n",
        "plt.plot(X_train[['Height']],regressor.predict(X_train),color=\"red\",linewidth=1)\n",
        "plt.plot(X_train[['Width']],regressor.predict(X_train),color=\"red\",linewidth=1)\n",
        "\n",
        "plt.title('regression training set')\n",
        "plt.xlabel('Independent')\n",
        "plt.ylabel('Weight')\n",
        "plt.show()\n",
        "\n",
        "#7. Predictions on the test set (apply the model)\n",
        "y_pred=regressor.predict(X_test)\n",
        "print(f\"r2 score {r2_score(y_test,y_pred)}\")\n",
        "print(f\"mean error { mean_squared_error(y_test,y_pred)}\")\n",
        "\n",
        "x = [[23.2,25.4,30,11.52,4.02]]\n",
        "Weight=regressor.predict(x)\n",
        "print(f\"Weight will be : {Weight}\")"
      ],
      "metadata": {
        "id": "A-BhGH371NSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Import the libraries\n",
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori,association_rules\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "\n",
        "#2.  Read the data, encode the data\n",
        "#create the sample dataset\n",
        "transactions = [['Bread','Milk'],\n",
        "                ['Bread','Diaper','Beer','Eggs'],\n",
        "                ['Milk','Diaper','Beer','Coke'],\n",
        "                ['Bread','Milk','Diaper','Beer'],\n",
        "                ['Bread','Milk','Diaper','Coke']]\n",
        "\n",
        "#transform it into the right format via Transactioon Encoder as follows:\n",
        "te=TransactionEncoder()\n",
        "te_arrary=te.fit(transactions).transform(transactions)\n",
        "df=pd.DataFrame(te_arrary,columns=te.columns_)\n",
        "print(df)\n",
        "\n",
        "#3. Find the frequent Itemsets\n",
        "freq_items=apriori(df,min_support=0.5,use_colnames=True)\n",
        "print(freq_items)\n",
        "\n",
        "#4. Generate the association rules\n",
        "rules = association_rules(freq_items,metric='support',min_threshold=0.05)\n",
        "rules = rules.sort_values(['support','confidence'],ascending=[False,False])\n",
        "print(rules)"
      ],
      "metadata": {
        "id": "48ORvHzr1NHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Import the libraries\n",
        "import csv\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import apriori\n",
        "from mlxtend.frequent_patterns import association_rules\n",
        "import pandas as pd\n",
        "\n",
        "#2.  Read the data, encode the data\n",
        "#create the sample dataset\n",
        "dataset = []\n",
        "with open('datasets/basket.csv','r') as csvfile:\n",
        "    reader = csv.reader(csvfile,delimiter=',')\n",
        "    for row in reader:\n",
        "        dataset+=[row]\n",
        "te = TransactionEncoder()\n",
        "data = te.fit_transform(dataset)\n",
        "data = pd.DataFrame(data,columns=te.columns_)\n",
        "print(data)\n",
        "print(data.shape)\n",
        "\n",
        "#3. Find the frequent Itemsets\n",
        "freq_items=apriori(data,min_support=0.5,use_colnames=True)\n",
        "print(freq_items)\n",
        "\n",
        "#4. Generate the association rules\n",
        "rules = association_rules(freq_items,metric='support',min_threshold=0.05)\n",
        "rules1 = association_rules(freq_items,metric='confidence',min_threshold=0.8)\n",
        "rules2 = association_rules(freq_items,metric='lift',min_threshold=10)\n",
        "rules = rules.sort_values(['support','confidence'],ascending=[False,False])\n",
        "print(rules)\n",
        "\n",
        "\"\"\" rules['ante_len'] = rules['antecedents'].apply(lambda x:len(x))\n",
        "nrules = rules[(rules['ante_len'] <= 3) &\n",
        "               (rules['confidence']>= 0.9) &\n",
        "               (rules['lift'] >= 2.0)]\n",
        "nrules = rules[rules['consequents'] == {'whole milk'}]\n",
        "nrules = rules[rules['antecedents'] == {'cereals','curd'}]\n",
        "nrules\n",
        "nrules = rules[['antecedents','consequents','confidence']]\n",
        "nrules.head()\n",
        "nrules.to_csv('rules.csv')\n",
        " \"\"\"\n",
        "\"\"\" Apriori algorithm\n",
        "\n",
        "4. Now, Convert Pandas DataFrame into a list of lists for encoding\n",
        "transactions = []\n",
        "for i in range(0, len(df)):\n",
        "transactions.append([str(df.values[i,j]) for j in range(0, len(df.columns))])\n",
        "5. Apply TransformEncoder to the transactions list\n",
        "6. Apply the apriori algorithm\n",
        " \"\"\""
      ],
      "metadata": {
        "id": "96a1MaTn1M6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGa25OGk1IYy"
      },
      "outputs": [],
      "source": [
        "#1. Import the libraries\n",
        "import csv\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import apriori\n",
        "from mlxtend.frequent_patterns import association_rules\n",
        "import pandas as pd\n",
        "\n",
        "#2.  Read the data, encode the data\n",
        "#create the sample dataset\n",
        "dataset = []\n",
        "with open('datasets/groceries.csv','r') as csvfile:\n",
        "    reader = csv.reader(csvfile,delimiter=',')\n",
        "    for row in reader:\n",
        "        dataset+=[row]\n",
        "te = TransactionEncoder()\n",
        "data = te.fit_transform(dataset)\n",
        "data = pd.DataFrame(data,columns=te.columns_)\n",
        "print(data)\n",
        "print(data.shape)\n",
        "\n",
        "#3. Find the frequent Itemsets\n",
        "freq_items=apriori(data,min_support=0.5,use_colnames=True)\n",
        "print(freq_items)\n",
        "\n",
        "#4. Generate the association rules\n",
        "rules = association_rules(freq_items,metric='support',min_threshold=0.05)\n",
        "#1. Import the libraries\n",
        "import csv\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import apriori\n",
        "from mlxtend.frequent_patterns import association_rules\n",
        "import pandas as pd\n",
        "\n",
        "#2.  Read the data, encode the data\n",
        "#create the sample dataset\n",
        "dataset = []\n",
        "with open('datasets/basket.csv','r') as csvfile:\n",
        "    reader = csv.reader(csvfile,delimiter=',')\n",
        "    for row in reader:\n",
        "        dataset+=[row]\n",
        "te = TransactionEncoder()\n",
        "data = te.fit_transform(dataset)\n",
        "data = pd.DataFrame(data,columns=te.columns_)\n",
        "print(data)\n",
        "print(data.shape)\n",
        "\n",
        "#3. Find the frequent Itemsets\n",
        "freq_items=apriori(data,min_support=0.5,use_colnames=True)\n",
        "print(freq_items)\n",
        "\n",
        "#4. Generate the association rules\n",
        "rules = association_rules(freq_items,metric='support',min_threshold=0.05)\n",
        "rules1 = association_rules(freq_items,metric='confidence',min_threshold=0.8)\n",
        "rules2 = association_rules(freq_items,metric='lift',min_threshold=10)\n",
        "rules = rules.sort_values(['support','confidence'],ascending=[False,False])\n",
        "print(rules)\n",
        "\n",
        "\"\"\" rules['ante_len'] = rules['antecedents'].apply(lambda x:len(x))\n",
        "nrules = rules[(rules['ante_len'] <= 3) &\n",
        "               (rules['confidence']>= 0.9) &\n",
        "               (rules['lift'] >= 2.0)]\n",
        "nrules = rules[rules['consequents'] == {'whole milk'}]\n",
        "nrules = rules[rules['antecedents'] == {'cereals','curd'}]\n",
        "nrules\n",
        "nrules = rules[['antecedents','consequents','confidence']]\n",
        "nrules.head()\n",
        "nrules.to_csv('rules.csv')\n",
        " \"\"\"\n",
        "\"\"\" Apriori algorithm\n",
        "\n",
        "4. Now, Convert Pandas DataFrame into a list of lists for encoding\n",
        "transactions = []\n",
        "for i in range(0, len(df)):\n",
        "transactions.append([str(df.values[i,j]) for j in range(0, len(df.columns))])\n",
        "5. Apply TransformEncoder to the transactions list\n",
        "6. Apply the apriori algorithm\n",
        " \"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the libraries\n",
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori,association_rules\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "\n",
        "#1.  Read the data, encode the data\n",
        "#create the sample dataset\n",
        "transactions = [['eggs', 'milk','bread'],\n",
        "                ['eggs', 'apple'],\n",
        "                ['milk', 'bread'],\n",
        "                ['apple', 'milk'],\n",
        "                ['milk', 'apple', 'bread']]\n",
        "\n",
        "#transform it into the right format via Transactioon Encoder as follows:\n",
        "te=TransactionEncoder()\n",
        "te_arrary=te.fit(transactions).transform(transactions)\n",
        "df=pd.DataFrame(te_arrary,columns=te.columns_)\n",
        "print(df)\n",
        "\n",
        "#3. Find the frequent Itemsets\n",
        "freq_items=apriori(df,min_support=0.5,use_colnames=True)\n",
        "print(freq_items)\n",
        "\n",
        "#4. Generate the association rules\n",
        "rules = association_rules(freq_items,metric='support',min_threshold=0.05)\n",
        "rules = rules.sort_values(['support','confidence'],ascending=[False,False])\n",
        "print(rules)"
      ],
      "metadata": {
        "id": "MN6upcst1gsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the libraries\n",
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori,association_rules\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "\n",
        "#1.  Read the data, encode the data\n",
        "#create the sample dataset\n",
        "transactions = [['eggs', 'milk','bread'],\n",
        "                ['eggs', 'apple'],\n",
        "                ['milk', 'bread'],\n",
        "                ['apple', 'milk'],\n",
        "                ['milk', 'apple', 'bread']]\n",
        "\n",
        "#transform it into the right format via Transactioon Encoder as follows:\n",
        "te=TransactionEncoder()\n",
        "te_arrary=te.fit(transactions).transform(transactions)\n",
        "df=pd.DataFrame(te_arrary,columns=te.columns_)\n",
        "print(df)\n",
        "\n",
        "#3. Find the frequent Itemsets\n",
        "freq_items=apriori(df,min_support=0.5,use_colnames=True)\n",
        "print(freq_items)\n",
        "\n",
        "#4. Generate the association rules\n",
        "rules = association_rules(freq_items,metric='support',min_threshold=0.05)\n",
        "rules = rules.sort_values(['support','confidence'],ascending=[False,False])\n",
        "print(rules)"
      ],
      "metadata": {
        "id": "LSbQJjOK1jg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the libraries\n",
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori,association_rules\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "\n",
        "#1.  Read the data, encode the data\n",
        "#create the sample dataset\n",
        "transactions = [['butter','bread','milk'],\n",
        "                ['butter',' flour','milk','sugar'],\n",
        "                ['butter', 'eggs', 'milk','salt'],\n",
        "                ['eggs'],\n",
        "                ['butter','flour','milk','salt']]\n",
        "\n",
        "#transform it into the right format via Transactioon Encoder as follows:\n",
        "te=TransactionEncoder()\n",
        "te_arrary=te.fit(transactions).transform(transactions)\n",
        "df=pd.DataFrame(te_arrary,columns=te.columns_)\n",
        "print(df)\n",
        "\n",
        "#3. Find the frequent Itemsets\n",
        "freq_items=apriori(df,min_support=0.5,use_colnames=True)\n",
        "print(freq_items)\n",
        "\n",
        "#4. Generate the association rules\n",
        "rules = association_rules(freq_items,metric='support',min_threshold=0.05)\n",
        "rules = rules.sort_values(['support','confidence'],ascending=[False,False])\n",
        "print(rules)"
      ],
      "metadata": {
        "id": "oqVFO4hA1mLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the libraries\n",
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori,association_rules\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "\n",
        "#1.  Read the data, encode the data\n",
        "#create the sample dataset\n",
        "transactions = [['Bread','Milk'],\n",
        "                ['Bread','Diaper','Beer','Eggs'],\n",
        "                ['Milk','Diaper','Beer','Coke'],\n",
        "                ['Bread','Milk','Diaper','Beer'],\n",
        "                ['Bread','Milk','Diaper','Coke']]\n",
        "\n",
        "#transform it into the right format via Transactioon Encoder as follows:\n",
        "te=TransactionEncoder()\n",
        "te_arrary=te.fit(transactions).transform(transactions)\n",
        "df=pd.DataFrame(te_arrary,columns=te.columns_)\n",
        "print(df)\n",
        "\n",
        "#3. Find the frequent Itemsets\n",
        "freq_items=apriori(df,min_support=0.5,use_colnames=True)\n",
        "print(freq_items)\n",
        "\n",
        "#4. Generate the association rules\n",
        "rules = association_rules(freq_items,metric='support',min_threshold=0.05)\n",
        "rules = rules.sort_values(['support','confidence'],ascending=[False,False])\n",
        "print(rules)"
      ],
      "metadata": {
        "id": "37fZ5VcF1od8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the libraries\n",
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori,association_rules\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "\n",
        "#1.  Read the data, encode the data\n",
        "#create the sample dataset\n",
        "transactions = [['Apple','Mango','Banana'],\n",
        "                ['Mango','Banana','Cabbage','Carrots'],\n",
        "                ['Mango','Banana','Carrots'],\n",
        "                ['Mango','Carrots']]\n",
        "\n",
        "#transform it into the right format via Transactioon Encoder as follows:\n",
        "te=TransactionEncoder()\n",
        "te_arrary=te.fit(transactions).transform(transactions)\n",
        "df=pd.DataFrame(te_arrary,columns=te.columns_)\n",
        "print(df)\n",
        "\n",
        "#3. Find the frequent Itemsets\n",
        "freq_items=apriori(df,min_support=0.5,use_colnames=True)\n",
        "print(freq_items)\n",
        "\n",
        "#4. Generate the association rules\n",
        "rules = association_rules(freq_items,metric='support',min_threshold=0.05)\n",
        "rules = rules.sort_values(['support','confidence'],ascending=[False,False])\n",
        "print(rules)"
      ],
      "metadata": {
        "id": "pfatFHqK1q9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Import libraries/packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score,mean_squared_error\n",
        "\n",
        "#2. Loading the data\n",
        "df = pd.read_csv('datasets/User_Data.csv')\n",
        "print(df.sample(5))\n",
        "print(df.shape)\n",
        "print(df.value_counts())\n",
        "print(df.isnull().sum())\n",
        "print(df.columns)\n",
        "df.dropna()\n",
        "print(df.shape)\n",
        "\n",
        "X=np.array(df[['EstimatedSalary']])\n",
        "y=np.array(df[['Purchased']])\n",
        "\n",
        "\"\"\"\n",
        "X =  df[['Height']]\n",
        "y = df['Weight']\n",
        " \"\"\"\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "\n",
        "#3. Visualizing the data\n",
        "plt.scatter(X,y,color=\"red\")\n",
        "plt.title('Estimated Salary vs Purchased')\n",
        "plt.xlabel('Estimated Salary')\n",
        "plt.ylabel('Purchased')\n",
        "plt.show()\n",
        "\n",
        "#4. Splitting our Data set in Dependent and Independent variables.\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.30,random_state=15)\n",
        "\n",
        "#5. Performing simple linear regression\n",
        "regressor= LinearRegression()\n",
        "regressor.fit(X_train,y_train)\n",
        "#Test Accuracy\n",
        "accuracy = regressor.score(X_test,y_test)\n",
        "print(\"\\n\\n Accuracy of model =\",accuracy)\n",
        "print(\"Coeficients\",regressor.coef_)\n",
        "print(\"Intercepts\",regressor.intercept_)\n",
        "\n",
        "#6. Residual analysis(Check the results of model fitting to know whether the model is satisfactory)\n",
        "plt.scatter(X_test,y_test,color='green')\n",
        "plt.plot(X_train,regressor.predict(X_train),color=\"red\",linewidth=3)\n",
        "plt.title('Regression(Test Set)')\n",
        "plt.xlabel('Estimated Salary')\n",
        "plt.ylabel('Purchased')\n",
        "plt.show()\n",
        "plt.scatter(X_train,y_train,color=\"blue\")\n",
        "plt.plot(X_train,regressor.predict(X_train),color=\"red\",linewidth=3)\n",
        "plt.title('regression training set')\n",
        "plt.xlabel('Estimated Salary')\n",
        "plt.ylabel('Purchased')\n",
        "plt.show()\n",
        "\n",
        "#7. Predictions on the test set (apply the model)\n",
        "y_pred=regressor.predict(X_test)\n",
        "print(f\"r2 score {r2_score(y_test,y_pred)}\")\n",
        "print(f\"mean error { mean_squared_error(y_test,y_pred)}\")\n",
        "\n",
        "Height = 165\n",
        "result=regressor.predict(np.array(Height).reshape(1,-1))\n",
        "Weight=result[0,0]\n",
        "print(f\"Weight will be : {Weight}\")"
      ],
      "metadata": {
        "id": "oyUwI6z41tS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the libraries\n",
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori,association_rules\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "\n",
        "#1.  Read the data, encode the data\n",
        "#create the sample dataset\n",
        "transactions = [['Bread','Milk'],\n",
        "                ['Bread','Diaper','Beer','Eggs'],\n",
        "                ['Milk','Diaper','Beer','Coke'],\n",
        "                ['Bread','Milk','Diaper','Beer'],\n",
        "                ['Bread','Milk','Diaper','Coke']]\n",
        "\n",
        "#transform it into the right format via Transactioon Encoder as follows:\n",
        "te=TransactionEncoder()\n",
        "te_arrary=te.fit(transactions).transform(transactions)\n",
        "df=pd.DataFrame(te_arrary,columns=te.columns_)\n",
        "print(df)\n",
        "\n",
        "#3. Find the frequent Itemsets\n",
        "freq_items=apriori(df,min_support=0.5,use_colnames=True)\n",
        "print(freq_items)\n",
        "\n",
        "#4. Generate the association rules\n",
        "rules = association_rules(freq_items,metric='support',min_threshold=0.05)\n",
        "rules = rules.sort_values(['support','confidence'],ascending=[False,False])\n",
        "print(rules)"
      ],
      "metadata": {
        "id": "QO3tAhcj1x3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Import libraries/packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score,mean_squared_error\n",
        "\n",
        "#2. Loading the data\n",
        "df = pd.read_csv('datasets/Car.csv')\n",
        "df = df[df['Make']=='Audi']\n",
        "print(df.shape)\n",
        "print(df.isnull().sum())\n",
        "print(df.columns)\n",
        "df = df.dropna()\n",
        "print(df.shape)\n",
        "print(df.sample(5))\n",
        "\n",
        "X=np.array(df[['EngineHP']]) #X = df[['']]\n",
        "y=np.array(df[['MSRP']]) #y = df['']\n",
        "\n",
        "#3. Visualizing the data\n",
        "plt.scatter(X,y,color=\"red\")\n",
        "plt.title('EngineHP vs MSRP')\n",
        "plt.xlabel('EngineHP')\n",
        "plt.ylabel('MSRP')\n",
        "plt.show()\n",
        "\n",
        "#4. Splitting our Data set in Dependent and Independent variables.\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.30,random_state=15)\n",
        "\n",
        "#5. Performing simple linear regression\n",
        "regressor= LinearRegression()\n",
        "regressor.fit(X_train,y_train)\n",
        "#Test Accuracy\n",
        "accuracy = regressor.score(X_test,y_test)\n",
        "print(\"\\n\\n Accuracy of model =\",accuracy)\n",
        "print(\"Coeficients\",regressor.coef_)\n",
        "print(\"Intercepts\",regressor.intercept_)\n",
        "\n",
        "#6. Residual analysis(Check the results of model fitting to know whether the model is satisfactory)\n",
        "plt.scatter(X_test,y_test,color='green')\n",
        "plt.plot(X_train,regressor.predict(X_train),color=\"red\",linewidth=3)\n",
        "plt.title('Regression(Test Set)')\n",
        "plt.xlabel('EngineHP')\n",
        "plt.ylabel('MSRP')\n",
        "plt.show()\n",
        "plt.scatter(X_train,y_train,color=\"blue\")\n",
        "plt.plot(X_train,regressor.predict(X_train),color=\"red\",linewidth=3)\n",
        "plt.title('regression training set')\n",
        "plt.xlabel('EngineHP')\n",
        "plt.ylabel('MSRP')\n",
        "plt.show()\n",
        "\n",
        "#7. Predictions on the test set (apply the model)\n",
        "y_pred=regressor.predict(X_test)\n",
        "print(f\"r2 score {r2_score(y_test,y_pred)}\")\n",
        "print(f\"mean error { mean_squared_error(y_test,y_pred)}\")\n",
        "\n",
        "EngineHP = 276\n",
        "result=regressor.predict(np.array(EngineHP).reshape(1,-1))\n",
        "MSRP=result[0,0]\n",
        "print(f\"MSRP will be : {MSRP}\")"
      ],
      "metadata": {
        "id": "ruYsnM7t10kZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the libraries\n",
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori,association_rules\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "\n",
        "#1.  Read the data, encode the data\n",
        "#create the sample dataset\n",
        "transactions = [['eggs', 'milk','bread'],\n",
        "                ['eggs', 'apple'],\n",
        "                ['milk', 'bread'],\n",
        "                ['apple','milk'],\n",
        "                ['milk','apple','bread']]\n",
        "\n",
        "#transform it into the right format via Transactioon Encoder as follows:\n",
        "te=TransactionEncoder()\n",
        "te_arrary=te.fit(transactions).transform(transactions)\n",
        "df=pd.DataFrame(te_arrary,columns=te.columns_)\n",
        "print(df)\n",
        "\n",
        "#3. Find the frequent Itemsets\n",
        "freq_items=apriori(df,min_support=0.5,use_colnames=True)\n",
        "print(freq_items)\n",
        "\n",
        "#4. Generate the association rules\n",
        "rules = association_rules(freq_items,metric='support',min_threshold=0.05)\n",
        "rules = rules.sort_values(['support','confidence'],ascending=[False,False])\n",
        "print(rules)"
      ],
      "metadata": {
        "id": "-XNkd0SE13BQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "df = pd.read_csv(\"data.csv\")\n",
        "print(df)\n",
        "print(df.head())\n",
        "print(df.tail())\n",
        "print(\"Dataset Info\")\n",
        "#q2\n",
        "print(df.shape)\n",
        "print(df.size)\n",
        "print(df.dtypes)\n",
        "#q3\n",
        "print(\"basic statisticsl details:\")\n",
        "print(df.describe())\n",
        "#q4\n",
        "print(\"\\n sum of None values\\n\",df.isna(),sum())\n",
        "print(\"\\n total duplicate values\\n\",df.duplicated(),sum())\n",
        "print(\"\\n total no. of record \\n\",df.size())\n",
        "#q5\n",
        "df['BMI'] = (df['weight'])/(df['height']**2)\n",
        "#q6\n",
        "print(\"maximum BMI : \",max(df['BMI']))\n",
        "print(\"minimum BMI : \",min(df['BMI']))\n",
        "#q7\n",
        "plt.scatter(df['height'],df['weight'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vKPLxhyS16dV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}